<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
    <title>Omega - Clubhouse GPT-3 bot - Lord Ajax</title>
  <meta name="description" content="i write software and shitty poetry">
  <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:title" content="Omega - Clubhouse GPT-3 bot - Lord Ajax" />

  <!-- Place favicon.ico in the root directory -->
  <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200;300;400;500;600&display=swap" rel="stylesheet">
  <meta name="theme-color" content="#fafafa">
  <link rel="stylesheet" href="/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.0/styles/solarized-dark.min.css" />
</head>

<body>
  <div class="container">
    <div class="title">Lord Ajax</div>
    <div class="byline">i write software and shitty poetry</div>
    <div class="pages">
      <a href="/">Home</a>
        <a href="/Contact">Contact</a>
        <a href="/About">About</a>
    </div>

    <div class="content">
      <h1>Omega - Clubhouse GPT-3 bot</h1>
<p>It's a conversational bot that leverages GPT-3 to reply contextually to speakers in Clubhouse topics. It uses Google Speech to translate peoples audio responses into text. The text is then sent to GPT-3 with a default prompt (persona).</p>
<p>The bot also contains multiple variations of &quot;personas&quot;, it tries to redirect responses from speakers in Clubhouse to an appropriate personality. In the GPT-3 prompt this codebase is configured to inject primitive &quot;memories&quot; that are generated by calls to GPT-3 through it's classification methodology. (in some lazy attempt to make the &quot;personas&quot; evolve over time)
Once GPT-3 replies with a textual response, it triggers Omega to do &quot;text-to-speech&quot; that plays the audio stream into Clubhouse.</p>
<p>The output voice is generated by Google speech and configured to use the &quot;personas&quot; speech profile. The file is saved, then streamed back through the local computers virtual audio device. (VB - Audio Control)
At this point, people in clubhouse should be able to have a back and fourth with GPT-3.</p>
<p><a href="https://github.com/thomasdavis/omega">https://github.com/thomasdavis/omega</a> - The code is all open source</p>
<p><a href="https://www.youtube.com/watch?v=XoSjVnUVu_U">https://www.youtube.com/watch?v=XoSjVnUVu_U</a> - 15 minute demonstration of the bot in action</p>
<embed goes here>
<!-- TOC titleSize:3 tabSpaces:2 depthFrom:2 depthTo:7 withLinks:0 updateOnSave:1 orderedList:1 skip:0 title:1 charForUnorderedList:* -->
<h3>Table of Contents</h3>
<pre><code>1. Implementation
  1. Clubhouse / Clubdeck
  2. VB Audio control
  3. Omega / Node.js
    1. Speech To Text
    2. GPT-3 Response
      1. BIO
      2. MEMORIES
      3. DEFAULT_CONVERSATION
      4. PREVIOUS_CONVERSATION
      5. NEW_CONVERSATION
    3. Text To speech
2. Conclusion
3. Next steps
4. Credits
</code></pre>
<!-- /TOC -->
<h3>Implementation</h3>
<p>The bot is a bit finicky to get working (currently only works on Windows to my chagrin, I am a life long Linux user).</p>
<p>I encountered varying limitations at every step of getting this work e.g. audio drivers, OS restrictions for different tools in the chain. Thus the code isn't as ideal as I'd have liked.</p>
<h4>Clubhouse / Clubdeck</h4>
<p>The first piece required is a third party non-official desktop client for Clubhouse called Clubdeck.</p>
<p>Clubdeck allows us to redirect audio in/out to the correct places.</p>
<p>I signed up for a <a href="https://twilio.com">Twilio</a> number to register a new account for the bot demo.</p>
<p>Download: <a href="https://www.clubdeck.app/">https://www.clubdeck.app/</a></p>
<h4>VB Audio control</h4>
<p>VB Audio control is an old windows program that is still in development that allows people to make virtual audio devices for playback and recording purposes.</p>
<p>You can install the minimal free version and this should give you the ability to add  new audio devices;</p>
<p>Playback: CABLE Input (VB-Audio Virtual Cable)
Recording: CABLE Output (VB-Audio Virtual Cable)</p>
<p>Download: <a href="https://vb-audio.com/Cable/">https://vb-audio.com/Cable/</a></p>
<h4>Omega / Node.js</h4>
<p>The node.js client is responsible for listening to Clubdeck output, turning audio into transcripts, sending prompt + transcript to GPT-3, taking the GPT-3 response, turning it into an audio speech file and then playing it into Clubdeck's virtual microphone.</p>
<p>I made a simple diagram to show the basic flow -&gt; <a href="https://i.imgur.com/2UcWUa6.jpg">https://i.imgur.com/2UcWUa6.jpg</a></p>
<h5>Speech To Text</h5>
<p>Speech to text is currently done by a library that boots up a headless chrome browser and leverages the built in speech to text functionality.</p>
<p><a href="https://github.com/DedaDev/wsrn">https://github.com/DedaDev/wsrn</a></p>
<p>You could actually just use Google Speech Node.js library but I couldn't get it working at the time so just opted for wsrn. (It is a high priority task to get Googles speech library integrated because it is much more flexible)</p>
<p>Now we have a textual version of people talking on Clubhouse, let's do something with it.</p>
<h5>GPT-3 Response</h5>
<p>GPT-3 takes one prompt which it uses to generate a response. There are a lot of <a href="https://beta.openai.com/docs/api-reference/completions">different ways</a> you can structure a prompt for GPT-3.</p>
<p>In the context of Omega, we want to make GPT-3 think it is having a conversation.</p>
<p>The prompt made for Omega bots personas follows this structure.</p>
<pre class="hljs"><code>BIO
MEMORIES
DEFAULT_CONVERSATION (a static manually defined conversation)
PREVIOUS_CONVERSATION (the last 6-8 messages saved)
NEW_TRANSCRIPTION (the latest speech to text)
</code></pre>
<h6>BIO</h6>
<p>The bio is used to setup the idea that GPT-3 is about to have a conversation and describes the traits of the persona. You can get quite creative but this template has worked well for the current personas.</p>
<p>Note: For the rest of these examples <code>botName=Omega</code> and <code>name=People</code></p>
<pre class="hljs"><code>The following is a conversation with ${botName}. ${botName} is a AI bot created by Ajax. ${botName} likes to have very philosophical conversations. ${botName} is sitting around in a room with a bunch of people having a discussion. ${botName} is extremely intelligent, funny and sardonic. He is talking to the people in the room.

${botName} lives in Ajax's house.
</code></pre>
<h6>MEMORIES</h6>
<p>Generally a GPT-3 bot will have a static prompt, memories were introduced as an experimental feature to try make personas evolve over time in a very primitive fashion.</p>
<p>Every time GPT-3 replies, the node client maintains a log of all the conversations it has had.</p>
<p>So we send off a background task to also log some memories. The way it does this is by using another type of GPT-3 prompt called a classification.</p>
<p>This prompt gets passed the last 6-8 messages of conversation, then tries to classify it, and then logs the GPT-3 response as a memory.</p>
<p>This is the current prompt for GPT-3 to attempt to classify the last messages;</p>
<pre class="hljs"><code>${name} and some people were having a conversation, my students asked me what they were talking about:
&quot;&quot;&quot;
${messages}
&quot;&quot;&quot;
The above was a conversation between ${name} and the people.
I wrote an explanation of the conversation below.
I explained to my students in plain english what the conversation was about:
&quot;&quot;&quot;
The conversation was about:
</code></pre>
<p>Here are some example memories it has created.</p>
<pre class="hljs"><code>a utopic timeline for humanity
the future
all the possible businesses you could do on the Moon or Mars
the conversation of robots and their automation ability in the future
the changes that facebook will implement in there profile picture
whether the new thing is a robot or not
</code></pre>
<p>Nothing too great but it has been able generate interesting responses. A cool feature of Omega is that it is able to reference other personas such as Chad or Nate. e.g.</p>
<pre class="hljs"><code>Chad: I like cookies
People: Hey Omega, does Chad like cookies?
Omega: Yes
</code></pre>
<p>With more work (persistent query database), I believe this could actually work quite nicely.</p>
<h6>DEFAULT_CONVERSATION</h6>
<p>We are going to insert dynamic transcripts from Clubhouse eventually, but it's really good to always include a default/original bot that gives the persona an idea of how it is suppose to talk e.g. long, articulate and factual</p>
<p>The current default conversational prompt for the &quot;Omega&quot; persona goes;</p>
<pre class="hljs"><code>${name}:Hey ${botName}, we love you, can you please tell us the meaning of life?
${botName}:As far as we can tell from a purely scientific viewpoint, human life has absolutely no meaning. Humans are the outcome of blind evolutionary processes that operate without goal or purpose. Our actions are not part of some divine cosmic plan, and if planet earth were to blow up tomorrow morning, the universe would probably keep going about its business as usual. As far as we can tell at this point, human subjectivity would not be missed. Hence any meaning that people inscribe to their lives is just a delusion.
${name}:Thank you for sharing your knowledge. I have another question for you, what do you think love is?
${botName}:To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.
</code></pre>
<p>So the &quot;Omega&quot; bot will always have the above as a scaffold for it's prompt.</p>
<p>It needs this because as &quot;Omega&quot; starts coming up with responses they also get appended to the prompt, and you could end up with a very silly bot. Imagine the scenario where people are just asking it basic questions;</p>
<pre class="hljs"><code>People: What is your favorite color?
Omega: Blue
People: What is your favorite animal?
Omega: Whale
</code></pre>
<p>Those messages get appended to &quot;Omega&quot; prompt, and if we just had a series of those transcriptions as it's persona, then it will eventually just talk like that all the time e.g.</p>
<pre class="hljs"><code>People: What is the universe?
Omega: It's big
</code></pre>
<p>Hopefully this will make more sense as we talk about the next segments of the prompt.</p>
<h6>PREVIOUS_CONVERSATION</h6>
<p>So as people talk and as the persona replies, everything is recorded into a transcript file so the bot always has an idea of what has been said previously, generally we only pop off 4-8 messages of the transcription log e.g.</p>
<pre class="hljs"><code>People:What is the meaning of life?
Omega:We should start by saying that there is no meaning in life outside of that which we can find by ourselves as a species. There isnâ€™t any kind of objective meaning written in the stars, in a holy book or in sequences of DNA.
People:What is the holy book?
Omega:The holy book generally refers to the Bible in the west.
</code></pre>
<p>So these previous discussions between people and &quot;Omega&quot; will also get appended to the prompt to send to GPT-3.</p>
<p>This helps the personas have a bit more of a memory of what was previously said.</p>
<p>Lastly, we want to append the latest thing somebody has said.</p>
<h6>NEW_CONVERSATION</h6>
<p>So we have constructed the majority of our prompt, by adding the BIO, MEMORIES, DEFAULT_CONVERSATION and PREVIOUS_CONVERSATION.</p>
<p>All we have to do now is add the last thing a person said on Clubhouse.</p>
<p>Once someone finishes speaking, we transcribe it to text this becomes last sequence of the prompt as such;</p>
<pre class="hljs"><code>People:Did you understand what I previously said?
Omega:
</code></pre>
<p>That last line of the prompt <code>Omega:</code> tells GPT-3 that it now wants a response to the conversation.</p>
<p>GPT-3 sends back a response like this;</p>
<pre class="hljs"><code>{
  &quot;id&quot;: &quot;cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7&quot;,
  &quot;object&quot;: &quot;text_completion&quot;,
  &quot;created&quot;: 1589478378,
  &quot;model&quot;: &quot;davinci:2020-05-03&quot;,
  &quot;choices&quot;: [
    {
      &quot;text&quot;: &quot;Omega:Yes, I did understand what you said previously&quot;,
      &quot;index&quot;: 0,
      &quot;logprobs&quot;: null,
      &quot;finish_reason&quot;: &quot;length&quot;
    }
  ]
}
</code></pre>
<p>The &quot;text&quot; is now added to the local transcript and thus will be included in the next prompt under the PREVIOUS_CONVERSATION.</p>
<p>That concludes how the prompts are constructed and how we interact with GPT-3.</p>
<h5>Text To speech</h5>
<p>Once GPT-3 responds, we simply trigger it to play back through the virtual audio output device.</p>
<p>Each persona has a voice configuration which leverages Google Deep Voice e.g.</p>
<pre class="hljs"><code>audioConfig: {
  audioEncoding: &quot;LINEAR16&quot;,
  pitch: -7.6,
  speakingRate: 0.87,
},
voice: {
  languageCode: &quot;en-US&quot;,
  name: &quot;en-US-Wavenet-J&quot;,
},
</code></pre>
<p>You can find voices at <a href="https://cloud.google.com/text-to-speech">https://cloud.google.com/text-to-speech</a></p>
<h3>Conclusion</h3>
<p>This has just been a fun project to play with, all the code is open source and would love to answer anyone's questions. I will probably keep adding new features and refinements over time.</p>
<p>I sometimes run the bot on Clubhouse, it's username is @omegadone.</p>
<h3>Next steps</h3>
<p>These are just some ideas for improvements to be made;</p>
<ul>
<li>At the moment there is no way to delineate who is speaking on Clubdeck. The bot currently replies to the prompt as if everyone were the same person.</li>
<li>We could store memories in a database, and try to query for a relevant memory to be inserted into the prompt.</li>
<li>Bring in better libraries for audio translation. Stop and start at more human-like times instead of how it currently works as a game of tennis.</li>
<li>Do a &quot;social-turing&quot; test run on Clubhouse.</li>
</ul>
<h3>Credits</h3>
<ul>
<li>All of the technologies already referenced in this post</li>
<li>All of the clubhouse folk who have been playing with Omega</li>
</ul>
<p>todo:</p>
<ul>
<li>Video demo embed</li>
<li>Stats</li>
</ul>


    </div>
    <br />
    Built by <a href="https://github.com/jsonblog/jsonblog-cli">JSON Blog</a>
  </div>
</body>

</html>
