<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
    <title>Omega WIP - Lord Ajax</title>
  <meta name="description" content="hopefully someone likes this">
  <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:title" content="Omega WIP - Lord Ajax" />

  <!-- Place favicon.ico in the root directory -->
  <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200;300;400;500;600&display=swap" rel="stylesheet">
  <meta name="theme-color" content="#fafafa">
  <link rel="stylesheet" href="/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.0/styles/solarized-dark.min.css" />
</head>

<body>
  <div class="container">
    <div class="title">Lord Ajax</div>
    <div class="byline">hopefully someone likes this</div>
    <div class="pages">
      <a href="/">Home</a>
        <a href="/Contact">Contact</a>
        <a href="/About">About</a>
    </div>

    <div class="content">
      <h1>Omega - Clubhouse GPT-3 bot</h1>
<p>This repo is code for a machine learning social &quot;turing&quot; test run on Clubhouse.
It's a conversational bot that leverages GPT-3 to reply contextually to speakers in Clubhouse topics. It uses Google Speech to translate peoples audio responses into text. (&quot;speech to text&quot;) The text is then sent to GPT-3 with a default prompt (personality).</p>
<p>The bot also contains multiple variations of &quot;personalities&quot;, it tries to redirect responses from speakers in Clubhouse to an appropriate personality. In the GPT-3 prompt this codebase is configured to inject primitive &quot;memories&quot; that are generated by calls to GPT-3 through it's classification methodology. (in some lazy attempt to make the &quot;personalities&quot; evolve over time)
Once GPT-3 replies with a textual response, it triggers Omega to do &quot;text-to-speech&quot; that plays the audio stream into Clubhouse.</p>
<p>The output voice is generated by Google speech and configured to use the &quot;personalities&quot; speech profile. The file is saved, then streamed back through the local computers audio device routing through the virtual audio device. (VB - Audio Control)
At this point, people in clubhouse should be able to have a back and fourth with GPT-3.</p>
<p><a href="https://github.com/thomasdavis/omega">https://github.com/thomasdavis/omega</a> - The code is all open source</p>
<p><a href="https://www.youtube.com/watch?v=XoSjVnUVu_U">https://www.youtube.com/watch?v=XoSjVnUVu_U</a> - 15 minute demonstration of the bot in action</p>
<!-- TOC titleSize:3 tabSpaces:2 depthFrom:2 depthTo:7 withLinks:1 updateOnSave:1 orderedList:1 skip:0 title:1 charForUnorderedList:* -->
<h3>Table of Contents</h3>
<pre><code>1. [Implementation](#implementation)
  1. [Clubhouse / Clubdeck](#clubhouse--clubdeck)
  2. [VB Audio control](#vb-audio-control)
  3. [Omega / Node.js](#omega--nodejs)
    1. [Speech To Text](#speech-to-text)
    2. [GPT-3 Response](#gpt-3-response)
      1. [BIO](#bio)
      2. [MEMORIES](#memories)
      3. [DEFAULT_CONVERSATION](#defaultconversation)
      4. [PREVIOUS_CONVERSATION](#previousconversation)
      5. [NEW_CONVERSATION](#newconversation)
    3. [Text To speech](#text-to-speech)
</code></pre>
<!-- /TOC -->
<h3>Implementation</h3>
<p>The bot is a bit finicky to get working (currently only works on Windows to my chagrin, I am a life long Linux user).</p>
<p>I encountered varying limitations at every step of getting this work e.g. audio drivers, OS restrictions for different tools in the chain.</p>
<h4>Clubhouse / Clubdeck</h4>
<p>The first piece required is a third party non-official desktop client for Clubhouse called Clubdeck.</p>
<p>Clubdeck allows us to redirect audio in/out to the correct places.</p>
<p>I signed up for a Twilio number to register a new account for the bot demo.</p>
<p>Download: <a href="https://www.clubdeck.app/">https://www.clubdeck.app/</a></p>
<h4>VB Audio control</h4>
<p>It is an old windows program that is still in development that allows people to make virtual audio devices for playback and recording purposes.</p>
<p>You can just install the minimal free version and this should give you a new audio devices;</p>
<p>Playback: CABLE Input (VB-Audio Virtual Cable)
Recording: CABLE Output (VB-Audio Virtual Cable)</p>
<p>Download: <a href="https://vb-audio.com/Cable/">https://vb-audio.com/Cable/</a></p>
<h4>Omega / Node.js</h4>
<p>The node.js client is responsible for listening to Clubdeck output, turning audio into transcript, sending prompt + transcript to GPT-3, taking the GPT-3 response, turning it into an audio speech file and then playing it into Clubdecks virtual microphone.</p>
<h5>Speech To Text</h5>
<p>Speech to text is currently done by a library that boots up a headless chrome browser and leverages the built in speech to text functionality.</p>
<p><a href="https://github.com/DedaDev/wsrn">https://github.com/DedaDev/wsrn</a></p>
<p>You can actually just use Google Speech Node.js library but I couldn't get it working at the time so just opted for wsrn. (It is in my high priority task to get Googles speech clietn in though because it is much more flexible)</p>
<p>Now we have a textual version of people talking on Clubhouse, let's do something with it.</p>
<h5>GPT-3 Response</h5>
<p>GPT-3 takes one prompt which it uses to generate a response. There are a lot of <a href="https://beta.openai.com/docs/api-reference/completions">different ways</a> you can structure a prompt for GPT-3.</p>
<p>In this context, we want to make GPT-3 is having a conversation.</p>
<p>The prompt made for Omega bot personas follows this structure.</p>
<pre class="hljs"><code>BIO
MEMORIES
DEFAULT_CONVERSATION (a static manually defined conversation)
PREVIOUS_CONVERSATION (the last 6-8 messages saved)
NEW_TRANSCRIPTION (the latest speech to text)
</code></pre>
<h6>BIO</h6>
<p>The bio is used to setup the idea that GPT-3 is about to have a conversation and describes the traits of the persona. You can get quite creative but this template has worked well for the current personas.</p>
<p>Note: For the rest of these examples <code>botName=Omega</code> and <code>name=People</code></p>
<pre class="hljs"><code>The following is a conversation with ${botName}. ${botName} is a AI bot created by Ajax. ${botName} likes to have very philosophical conversations. ${botName} is sitting around in a room with a bunch of people having a discussion. ${botName} is extremely intelligent, funny and sardonic. He is talking to the people in the room.

${botName} lives in Ajax's house.
</code></pre>
<h6>MEMORIES</h6>
<p>Generally a GPT-3 bot will have a static prompt, memories were introduced as an experimental feature to try make personas evolve over time in a very primitive fashion.</p>
<p>Every time GPT-3 replies the node client maintains a log of all the conversations it has had.</p>
<p>So we send off a background task to also log some memories. The way it does this is by using another type of GPT-3 prompt called a classification.</p>
<p>This prompt gets passed the last 6-8 messages of conversation, then tries to classify it, and then logs the GPT-3 as a memory.</p>
<pre class="hljs"><code>${name} and some people were having a conversation, my students asked me what they were talking about:
&quot;&quot;&quot;
${messages}
&quot;&quot;&quot;
The above was a conversation between ${name} and the people.
I wrote an explanation of the conversation below.
I explained to my students in plain english what the conversation was about:
&quot;&quot;&quot;
The conversation was about
</code></pre>
<p>Here are some example memories it has created.</p>
<pre class="hljs"><code>a utopic timeline for humanity
the future
all the possible businesses you could do on the Moon or Mars
the conversation of robots and their automation ability in the future
the changes that facebook will implement in there profile picture
whether the new thing is a robot or not
</code></pre>
<p>Nothing too great but it has been able generate interesting responses. A cool feature of Omega is that it is able to reference other personas such as Chad or Nate. e.g.</p>
<pre class="hljs"><code>Chad: I like cookies
People: Hey Omega, does Chad like cookies?
Omega: Yes
</code></pre>
<p>With more work (persistent query database) I believe this could actually work quite nicely.</p>
<h6>DEFAULT_CONVERSATION</h6>
<p>We are going to insert dynamic transcripts from Clubhouse eventually, but it's really good to always include a default/original bot that gives the persona an idea of how it is suppose to talk e.g. long, articulate and factual</p>
<p>The current default conversational prompt for the &quot;Omega&quot; persona goes;</p>
<pre class="hljs"><code>${name}:Hey ${botName}, we love you, can you please tell us the meaning of life?
${botName}:As far as we can tell from a purely scientific viewpoint, human life has absolutely no meaning. Humans are the outcome of blind evolutionary processes that operate without goal or purpose. Our actions are not part of some divine cosmic plan, and if planet earth were to blow up tomorrow morning, the universe would probably keep going about its business as usual. As far as we can tell at this point, human subjectivity would not be missed. Hence any meaning that people inscribe to their lives is just a delusion.
${name}:Thank you for sharing your knowledge. I have another question for you, what do you think love is?
${botName}:To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.
</code></pre>
<p>So the &quot;Omega&quot; bot will always have the above as a basic for it's prompt.</p>
<p>It needs this because as &quot;Omega&quot; starts coming up with responses they also get appended to the prompt, and you could end up with a very silly bot. Imagine the scenario where people are just asking it basic questions;</p>
<pre class="hljs"><code>People: What is your favorite color?
Omega: Blue
People: What is your favorite animal?
Omega: Whale
</code></pre>
<p>Those messages get appended to &quot;Omega&quot; prompt, and if we just had a series of those transcriptions as it's personality, then it will eventually just talk like that all the time e.g.</p>
<pre class="hljs"><code>People: What is the universe?
Omega: It's big
</code></pre>
<p>Hopefully this will make more sense as we talk about the next segments of the prompt.</p>
<h6>PREVIOUS_CONVERSATION</h6>
<p>So as people talk and as the persona replies, everything is recorded into a transcript file so the bot always has an idea of what has been said previously, generally we only pop off 4-8 messages of the transcript e.g.</p>
<pre class="hljs"><code>People:What is the meaning of life?
Omega:We should start by saying that there is no meaning in life outside of that which we can find by ourselves as a species. There isn’t any kind of objective meaning written in the stars, in a holy book or in sequences of DNA.
People:What is the holy book?
Omega:The holy book generally refers to the Bible in the west.
</code></pre>
<p>So these previous discussion between people and &quot;Omega&quot; will also get appended to the prompt to send to GPT-3.</p>
<p>This helps the personas have a bit more of a memory of what was previously said.</p>
<p>Lastly, we want to append the latest thing somebody has said.</p>
<h6>NEW_CONVERSATION</h6>
<p>So we have constructed the majority of our prompt, by adding the BIO, MEMORIES, DEFAULT_CONVERSATION and PREVIOUS_CONVERSATION.</p>
<p>All we have to do now is add the last thing a person said on Clubhouse.</p>
<p>Once someone finishes speaking, we transcribe it to text it generate the last sequence of the prompt as such;</p>
<pre class="hljs"><code>People:Did you understand what I previously said?
Omega:
</code></pre>
<p>That last line of the prompt <code>Omega:</code> tells GPT-3 that it now wants a response to the conversation.</p>
<p>GPT-3 sends back a response like this;</p>
<pre class="hljs"><code>{
  &quot;id&quot;: &quot;cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7&quot;,
  &quot;object&quot;: &quot;text_completion&quot;,
  &quot;created&quot;: 1589478378,
  &quot;model&quot;: &quot;davinci:2020-05-03&quot;,
  &quot;choices&quot;: [
    {
      &quot;text&quot;: &quot;Omega:Yes, I did understand what you said previously&quot;,
      &quot;index&quot;: 0,
      &quot;logprobs&quot;: null,
      &quot;finish_reason&quot;: &quot;length&quot;
    }
  ]
}
</code></pre>
<p>The &quot;text&quot; is now added to the local transcript and thus will be included in the next prompt under the PREVIOUS_CONVERSATION.</p>
<p>That concludes how the prompts are constructed and how we interact with GPT-3.</p>
<h5>Text To speech</h5>
<p>google deep voice
<a href="https://cloud.google.com/text-to-speech">https://cloud.google.com/text-to-speech</a>
notes:</p>
<ul>
<li>Video demo embed</li>
<li>Diagram</li>
<li>twilio for bot #</li>
<li>Cool things</li>
<li>Stats</li>
<li>Future plans</li>
<li>word wrapping code blocks</li>
<li>responsive
conclusion</li>
</ul>


    </div>
    <br />
    Built by <a href="https://github.com/jsonblog/jsonblog-cli">JSON Blog</a>
  </div>
</body>

</html>
